{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.13.1+cu116 torchaudio==0.13.1+cu116 torchvision==0.14.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "# !pip install transformers==4.35.2\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/AERA02_AptitudeAssessment_Dataset_NLP_cleaned_vi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def process_text(text):\n",
    "    text = re.sub(\"(&#\\d+;)\", \"\", text)\n",
    "    text = re.sub(\"([\\/-])\", \" \", text)\n",
    "    text = re.sub(\"(<.*?>)\", \"\" ,text)\n",
    "    text = re.sub(\"(^https?:\\/\\/\\S+)\", \"\", text)\n",
    "    text = \"\".join([i for i in text if i not in string.punctuation + \"…\"])\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def process_corpus(corpus):\n",
    "    _WORD_SPLIT = re.compile(\"([.,!?\\\"/':;)(])\")\n",
    "    def basic_tokenizer(sentence):\n",
    "        words = []\n",
    "        for space_separated_fragment in sentence.strip().split():\n",
    "            words.extend(_WORD_SPLIT.split(space_separated_fragment))\n",
    "        return [w.lower() for w in words if w != '' and w != ' ' and w not in string.punctuation]\n",
    "    \n",
    "    corpus = corpus.replace(\"\\n\", \" \").split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df[\"score\"].astype(\"int\")\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(process_text)\n",
    "df[\"title\"] = df[\"title\"].apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "\n",
    "\n",
    "class Config():\n",
    "    seed_val = 17\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    epochs = 8 \n",
    "    batch_size = 32\n",
    "    seq_length = 512\n",
    "    lr = 2e-5\n",
    "    eps = 1e-8\n",
    "    pretrained_model = 'bert-base-uncased'\n",
    "    test_size=0.15\n",
    "    random_state=42\n",
    "    add_special_tokens=True \n",
    "    return_attention_mask=True \n",
    "    pad_to_max_length=True \n",
    "    do_lower_case=True\n",
    "    return_tensors='pt'\n",
    "    cache_dir=\"/space/hotel/phit/personal/aera02-aisia/cache\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# params will be saved after training\n",
    "params = {\"seed_val\": config.seed_val,\n",
    "    \"device\":str(config.device),\n",
    "    \"epochs\":config.epochs, \n",
    "    \"batch_size\":config.batch_size,\n",
    "    \"seq_length\":config.seq_length,\n",
    "    \"lr\":config.lr,\n",
    "    \"eps\":config.eps,\n",
    "    \"pretrained_model\": config.pretrained_model,\n",
    "    \"test_size\":config.test_size,\n",
    "    \"random_state\":config.random_state,\n",
    "    \"add_special_tokens\":config.add_special_tokens,\n",
    "    \"return_attention_mask\":config.return_attention_mask,\n",
    "    \"pad_to_max_length\":config.pad_to_max_length,\n",
    "    \"do_lower_case\":config.do_lower_case,\n",
    "    \"return_tensors\":config.return_tensors,\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/val/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_, test_df = train_test_split(df, \n",
    "                                      test_size=0.10, \n",
    "                                      random_state=config.random_state, \n",
    "                                      stratify=df.score.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed_val):\n",
    "    # set random seed and device\n",
    "    import random\n",
    "\n",
    "    device = config.device\n",
    "\n",
    "    random.seed(config.seed_val)\n",
    "    np.random.seed(config.seed_val)\n",
    "    torch.manual_seed(config.seed_val)\n",
    "    torch.cuda.manual_seed_all(config.seed_val)\n",
    "    \n",
    "set_random_seed(config.seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df_, \n",
    "                                    test_size=0.10, \n",
    "                                    random_state=42, \n",
    "                            stratify=train_df_.score.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38914, 5), (4324, 5), (4805, 5))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.pretrained_model, \n",
    "                                          do_lower_case=config.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] this is example of tokenizer. [SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"This is example of tokenizer.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>title2review</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14223</th>\n",
       "      <td>5</td>\n",
       "      <td>nghỉ dưởng</td>\n",
       "      <td>hòn tầm phong cảnh rất đẹp  bãi biển cát trắng...</td>\n",
       "      <td>Nghỉ dưởng. Hòn Tầm phong cảnh rất đẹp , bãi b...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34363</th>\n",
       "      <td>5</td>\n",
       "      <td>chuyến đi tuyệt vời</td>\n",
       "      <td>mình và đồng nghiệp có dịp ghé đất quảng và cô...</td>\n",
       "      <td>Chuyến đi tuyệt vời . Mình và đồng nghiệp có d...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40890</th>\n",
       "      <td>5</td>\n",
       "      <td>trải nghiệm cuối tuần</td>\n",
       "      <td>khách sạn sạch sẽ    view đẹp    nhân viên n...</td>\n",
       "      <td>Trải nghiệm cuối tuần. - khách sạn sạch sẽ,  -...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17361</th>\n",
       "      <td>5</td>\n",
       "      <td>kì nghỉ trải nghiệm rất tuyệt vời</td>\n",
       "      <td>vợ chồng tôi ở khu nghỉ dưỡng dốc lếch này thấ...</td>\n",
       "      <td>Kì nghỉ trải nghiệm rất tuyệt vời. Vợ chồng tô...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40440</th>\n",
       "      <td>5</td>\n",
       "      <td>trải nghiệm tuyệt vời</td>\n",
       "      <td>khách sạn quá đẹp quá rộng rãi và thoáng mát n...</td>\n",
       "      <td>Trải nghiệm tuyệt vời. Khách sạn quá đẹp quá r...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>4</td>\n",
       "      <td>phòng rộng rãi</td>\n",
       "      <td>khách sạn 4 sao trang trí theo phong cách hoàn...</td>\n",
       "      <td>Phòng rộng rãi. Khách sạn 4 sao, trang trí the...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39902</th>\n",
       "      <td>5</td>\n",
       "      <td>banquet team</td>\n",
       "      <td>không gian sang trọng thiết kế độc đáo dịch vụ...</td>\n",
       "      <td>Banquet team. Không gian sang trọng, thiết kế ...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36763</th>\n",
       "      <td>5</td>\n",
       "      <td>đánh giá 5 sao</td>\n",
       "      <td>villa khá thoải mái rất gần trung tâm đầy đủ t...</td>\n",
       "      <td>Đánh giá 5 sao. Villa khá thoải mái, rất gần t...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43889</th>\n",
       "      <td>2</td>\n",
       "      <td>thất vọng</td>\n",
       "      <td>thất vọng về thái độ tiếp khách 3h sáng mình q...</td>\n",
       "      <td>thất vọng. thất vọng về thái độ tiếp khách, 3h...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11665</th>\n",
       "      <td>5</td>\n",
       "      <td>hoàng hảo</td>\n",
       "      <td>một trãi nghiệm ở huế tuyệt vời khách sạn sang...</td>\n",
       "      <td>Hoàng hảo. Một trãi nghiệm ở huế tuyệt vời, kh...</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38914 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score                              title  \\\n",
       "14223      5                         nghỉ dưởng   \n",
       "34363      5               chuyến đi tuyệt vời    \n",
       "40890      5              trải nghiệm cuối tuần   \n",
       "17361      5  kì nghỉ trải nghiệm rất tuyệt vời   \n",
       "40440      5              trải nghiệm tuyệt vời   \n",
       "...      ...                                ...   \n",
       "4331       4                     phòng rộng rãi   \n",
       "39902      5                       banquet team   \n",
       "36763      5                     đánh giá 5 sao   \n",
       "43889      2                          thất vọng   \n",
       "11665      5                          hoàng hảo   \n",
       "\n",
       "                                                  review  \\\n",
       "14223  hòn tầm phong cảnh rất đẹp  bãi biển cát trắng...   \n",
       "34363  mình và đồng nghiệp có dịp ghé đất quảng và cô...   \n",
       "40890    khách sạn sạch sẽ    view đẹp    nhân viên n...   \n",
       "17361  vợ chồng tôi ở khu nghỉ dưỡng dốc lếch này thấ...   \n",
       "40440  khách sạn quá đẹp quá rộng rãi và thoáng mát n...   \n",
       "...                                                  ...   \n",
       "4331   khách sạn 4 sao trang trí theo phong cách hoàn...   \n",
       "39902  không gian sang trọng thiết kế độc đáo dịch vụ...   \n",
       "36763  villa khá thoải mái rất gần trung tâm đầy đủ t...   \n",
       "43889  thất vọng về thái độ tiếp khách 3h sáng mình q...   \n",
       "11665  một trãi nghiệm ở huế tuyệt vời khách sạn sang...   \n",
       "\n",
       "                                            title2review language  \n",
       "14223  Nghỉ dưởng. Hòn Tầm phong cảnh rất đẹp , bãi b...       vi  \n",
       "34363  Chuyến đi tuyệt vời . Mình và đồng nghiệp có d...       vi  \n",
       "40890  Trải nghiệm cuối tuần. - khách sạn sạch sẽ,  -...       vi  \n",
       "17361  Kì nghỉ trải nghiệm rất tuyệt vời. Vợ chồng tô...       vi  \n",
       "40440  Trải nghiệm tuyệt vời. Khách sạn quá đẹp quá r...       vi  \n",
       "...                                                  ...      ...  \n",
       "4331   Phòng rộng rãi. Khách sạn 4 sao, trang trí the...       vi  \n",
       "39902  Banquet team. Không gian sang trọng, thiết kế ...       vi  \n",
       "36763  Đánh giá 5 sao. Villa khá thoải mái, rất gần t...       vi  \n",
       "43889  thất vọng. thất vọng về thái độ tiếp khách, 3h...       vi  \n",
       "11665  Hoàng hảo. Một trãi nghiệm ở huế tuyệt vời, kh...       vi  \n",
       "\n",
       "[38914 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a CustomDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.df.reset_index(drop=True, inplace=True)\n",
    "        self.df[\"encoded\"] = self.df.title.fillna(\"\") + f\" {tokenizer.sep_token} \" + self.df.review.fillna(\"\")\n",
    "        self.encoded = tokenizer.batch_encode_plus(list(df.encoded.apply(lambda x: x.replace(\"_\",\" \")).values), \n",
    "                                                max_length=config.seq_length, \n",
    "                                                add_special_tokens=config.add_special_tokens, \n",
    "                                                return_attention_mask=config.return_attention_mask, \n",
    "                                                pad_to_max_length=config.pad_to_max_length,\n",
    "                                                truncation=True)[\"input_ids\"]\n",
    "        # Check if the dataframe has the target column\n",
    "        if hasattr(self.df, \"score\"):\n",
    "            self.targets = self.df.score\n",
    "        else:\n",
    "            self.targets = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # review = str(self.review[index])\n",
    "        # review = \" \".join(review.split())\n",
    "        \n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(self.encoded[index]), \n",
    "            # Return None if the targets are None\n",
    "            'target': None if self.targets is None else torch.tensor(self.targets[index])\n",
    "        }\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/phit/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/space/hotel/phit/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset_train = CustomDataset(train_df, tokenizer)\n",
    "dataset_val = CustomDataset(val_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    ids = [x[\"ids\"] for x in batch]\n",
    "    targets = [x[\"target\"] for x in batch]\n",
    "    max_len = np.max([len(x) for x in ids])\n",
    "    masks = []\n",
    "    for i in range(len(ids)):\n",
    "        if len(ids[i]) < max_len:\n",
    "            ids[i]= torch.cat((ids[i], torch.tensor([pad_token_id,]*(max_len - len(ids[i])),dtype=torch.long)))\n",
    "        masks.append(ids[i] != pad_token_id)\n",
    "    # print(tokenizer.decode(ids[0]))\n",
    "    # Check if the target is None\n",
    "    if targets[0] is None:\n",
    "        # Return only ids and masks\n",
    "        outputs = {\n",
    "            \"ids\": torch.vstack(ids),\n",
    "            \"masks\": torch.vstack(masks)\n",
    "        }\n",
    "    else:\n",
    "        # Return ids, masks and target as before\n",
    "        outputs = {\n",
    "            \"ids\": torch.vstack(ids),\n",
    "            \"masks\": torch.vstack(masks),\n",
    "            \"target\": torch.vstack(targets).view(-1)\n",
    "        }\n",
    "    return outputs\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              collate_fn=collate_fn,\n",
    "                              batch_size=config.batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   collate_fn=collate_fn,\n",
    "                                   batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[  101,  1047,  3270,  ...,     0,     0,     0],\n",
       "         [  101,  2008,  3854,  ...,     0,     0,     0],\n",
       "         [  101, 22775,  5495,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  1047,  3270,  ...,     0,     0,     0],\n",
       "         [  101, 21722,   102,  ...,     0,     0,     0],\n",
       "         [  101, 18712, 12835,  ...,     0,     0,     0]]),\n",
       " 'masks': tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False]]),\n",
       " 'target': tensor([5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5,\n",
       "         4, 5, 5, 5, 5, 5, 5, 5])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and Load functions\n",
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "    if save_path is None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {\n",
    "                     'model_state_dict': model.state_dict(),\n",
    "                     'valid_loss': valid_loss\n",
    "                 }\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(load_path, model):\n",
    "    if load_path is None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "    if save_path is None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {\n",
    "                     'train_loss_list': train_loss_list,\n",
    "                     'valid_loss_list': valid_loss_list,\n",
    "                     'global_steps_list': global_steps_list\n",
    "                 }\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "   \n",
    "def load_metrics(load_path):\n",
    "    if load_path is None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'],state_dict['global_steps_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(config.pretrained_model,\n",
    "                                                      num_labels=6,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False,\n",
    "                                                      cache_dir=config.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "\n",
    "def optimizer_scheduler(model, num_train_steps):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.001,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "    opt = AdamW(optimizer_parameters, lr=3e-5)\n",
    "    sch = get_linear_schedule_with_warmup(\n",
    "        opt,\n",
    "        num_warmup_steps=int(0.05*num_train_steps),\n",
    "        num_training_steps=num_train_steps,\n",
    "        last_epoch=-1,\n",
    "    )\n",
    "    return opt, sch\n",
    "\n",
    "class BertTrainer:\n",
    "    \"\"\" A training and evaluation loop for PyTorch models with a BERT like architecture. \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model,\n",
    "        tokenizer,\n",
    "        train_dataloader,\n",
    "        eval_dataloader=None,\n",
    "        accumulation_steps=5,\n",
    "        epochs=1,\n",
    "        lr=5e-04,\n",
    "        output_dir='./',\n",
    "        output_filename='model_state_dict.pt',\n",
    "        save=False,\n",
    "        tabular=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: torch.nn.Module: = A PyTorch model with a BERT like architecture,\n",
    "            tokenizer: = A BERT tokenizer for tokenizing text input,\n",
    "            train_dataloader: torch.utils.data.DataLoader = \n",
    "                A dataloader containing the training data with \"text\" and \"label\" keys (optionally a \"tabular\" key),\n",
    "            eval_dataloader: torch.utils.data.DataLoader = \n",
    "                A dataloader containing the evaluation data with \"text\" and \"label\" keys (optionally a \"tabular\" key),\n",
    "            epochs: int = An integer representing the number epochs to train,\n",
    "            lr: float = A float representing the learning rate for the optimizer,\n",
    "            output_dir: str = A string representing the directory path to save the model,\n",
    "            output_filename: string = A string representing the name of the file to save in the output directory,\n",
    "            save: bool = A boolean representing whether or not to save the model,\n",
    "            tabular: bool = A boolean representing whether or not the BERT model is modified to accept tabular data,\n",
    "        \"\"\"\n",
    "        \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = model.to(self.device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.eval_dataloader = eval_dataloader\n",
    "        # num_train_steps = len(train_dataloader) * epochs // accumulation_steps\n",
    "        # self.optimizer, self.scheduler = optimizer_scheduler(self.model, num_train_steps)\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.output_dir = output_dir\n",
    "        self.output_filename = output_filename\n",
    "        self.save = save\n",
    "        self.eval_loss = float('inf')  # tracks the lowest loss so as to only save the best model  \n",
    "        self.epochs = epochs\n",
    "        self.epoch_best_model = 0  # tracks which epoch the lowest loss is in so as to only save the best model\n",
    "        \n",
    "        \n",
    "    def train(self, evaluate=False):\n",
    "        \"\"\" Calls the batch iterator to train and optionally evaluate the model.\"\"\"\n",
    "        for epoch in range(self.epochs):\n",
    "            self.iteration(epoch, self.train_dataloader)\n",
    "            if evaluate and self.eval_dataloader is not None:\n",
    "                self.iteration(epoch, self.eval_dataloader, train=False)\n",
    "                \n",
    "    def evaluate(self):\n",
    "        \"\"\" Calls the batch iterator to evaluate the model.\"\"\"\n",
    "        epoch=0\n",
    "        self.iteration(epoch, self.eval_dataloader, train=False)\n",
    "    \n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "        \"\"\" Iterates through one epoch of training or evaluation\"\"\"\n",
    "        \n",
    "        # initialize variables\n",
    "        loss_accumulated = 0.\n",
    "        correct_accumulated = 0\n",
    "        samples_accumulated = 0\n",
    "        preds_all = []\n",
    "        labels_all = []\n",
    "        \n",
    "        self.model.train() if train else self.model.eval()\n",
    "        \n",
    "        # progress bar\n",
    "        mode = \"train\" if train else \"eval\"\n",
    "        batch_iter = tqdm(\n",
    "            enumerate(data_loader),\n",
    "            desc=f\"EP ({mode}) {epoch}\",\n",
    "            total=len(data_loader),\n",
    "            bar_format=\"{l_bar}{r_bar}\"\n",
    "        )\n",
    "        \n",
    "        # iterate through batches of the dataset\n",
    "        for i, batch in batch_iter:\n",
    "\n",
    "            batch = {key: value.to(self.device) for key, value in batch.items()}\n",
    "\n",
    "            outputs = self.model(\n",
    "                input_ids=batch[\"ids\"], \n",
    "                attention_mask=batch[\"masks\"],\n",
    "                token_type_ids=None, \n",
    "                labels=batch[\"target\"]\n",
    "            )\n",
    "\n",
    "            # calculate loss\n",
    "            # loss = self.loss_fn(outputs, batch[\"label\"])\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "    \n",
    "            # compute gradient and and update weights\n",
    "            if train:\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            # calculate the number of correct predictions\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            correct = preds.eq(batch[\"target\"]).sum().item()\n",
    "            \n",
    "            # accumulate batch metrics and outputs\n",
    "            loss_accumulated += loss.item()\n",
    "            correct_accumulated += correct\n",
    "            samples_accumulated += len(batch[\"target\"])\n",
    "            preds_all.append(preds.detach())\n",
    "            labels_all.append(batch['target'].detach())\n",
    "            \n",
    "            batch_iter.set_postfix(loss=loss.item())\n",
    "        \n",
    "        # concatenate all batch tensors into one tensor and move to cpu for compatibility with sklearn metrics\n",
    "        preds_all = torch.cat(preds_all, dim=0).cpu()\n",
    "        labels_all = torch.cat(labels_all, dim=0).cpu()\n",
    "        \n",
    "        # metrics\n",
    "        accuracy = accuracy_score(labels_all, preds_all)\n",
    "        precision = precision_score(labels_all, preds_all, average='macro')\n",
    "        recall = recall_score(labels_all, preds_all, average='macro')\n",
    "        f1 = f1_score(labels_all, preds_all, average='macro')\n",
    "        avg_loss_epoch = loss_accumulated / len(data_loader)\n",
    "        \n",
    "        # print metrics to console\n",
    "        print(\n",
    "            f\"\"\"samples={samples_accumulated}, \\\n",
    "    correct={correct_accumulated}, \\\n",
    "    acc={round(accuracy, 4)}, \\\n",
    "    recall={round(recall, 4)}, \\\n",
    "    prec={round(precision,4)}, \\\n",
    "    f1={round(f1, 4)}, \\\n",
    "    loss={round(avg_loss_epoch, 4)}\"\"\"\n",
    "        )    \n",
    "        \n",
    "        # save the model if the evaluation loss is lower than the previous best epoch \n",
    "        if self.save and not train and avg_loss_epoch < self.eval_loss:\n",
    "            \n",
    "            # create directory and filepaths\n",
    "            dir_path = Path(self.output_dir)\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            file_path = dir_path / f\"{self.output_filename}_epoch_{epoch}.pt\"\n",
    "            \n",
    "            # delete previous best model from hard drive\n",
    "            if epoch > 0:\n",
    "                file_path_best_model = dir_path / f\"{self.output_filename}_epoch_{self.epoch_best_model}.pt\"\n",
    "                !rm -f $file_path_best_model\n",
    "            \n",
    "            # save model\n",
    "            torch.save({\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict()\n",
    "            }, file_path)\n",
    "            \n",
    "            # update the new best loss and epoch\n",
    "            self.eval_loss = avg_loss_epoch\n",
    "            self.epoch_best_model = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/phit/miniconda3/envs/llm/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3feda4b0a204e02b5aa6535081b845e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (train) 0:   0%|| 0/1217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=38914,     correct=32964,     acc=0.8471,     recall=0.3152,     prec=0.3759,     f1=0.3167,     loss=0.4657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/phit/miniconda3/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99adbda5b8dc44eea2a2549e40ef18f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 0:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/hotel/phit/miniconda3/envs/llm/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3739,     acc=0.8647,     recall=0.4573,     prec=0.4838,     f1=0.456,     loss=0.3784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab2445cd178473c8c4f1f9a7bbc42b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (train) 1:   0%|| 0/1217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=38914,     correct=33816,     acc=0.869,     recall=0.4966,     prec=0.5802,     f1=0.4982,     loss=0.3645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f6c325cffc42a39d3cc95ebfe2a4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 1:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3719,     acc=0.8601,     recall=0.5491,     prec=0.5614,     f1=0.5194,     loss=0.3877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b6558da67d4e2d98bf8afb5554219d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (train) 2:   0%|| 0/1217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=38914,     correct=34226,     acc=0.8795,     recall=0.5394,     prec=0.6047,     f1=0.5491,     loss=0.3302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a8151588ec473c8672a32e3f921221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 2:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3672,     acc=0.8492,     recall=0.5783,     prec=0.5437,     f1=0.5562,     loss=0.394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033bf5b4fdf24efca61e831564282aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (train) 3:   0%|| 0/1217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=38914,     correct=34637,     acc=0.8901,     recall=0.6002,     prec=0.6653,     f1=0.6186,     loss=0.2962\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39765eb0988844cda75255c88b90e548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 3:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3756,     acc=0.8686,     recall=0.5362,     prec=0.5658,     f1=0.5316,     loss=0.3759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make your changes take effect please reactivate your environment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7506b83892594ea0ab9f79f90beec6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (train) 4:   0%|| 0/1217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=38914,     correct=35106,     acc=0.9021,     recall=0.6436,     prec=0.702,     f1=0.6654,     loss=0.2623\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1afe6be25624d728eaad8db35f41993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 4:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3688,     acc=0.8529,     recall=0.5411,     prec=0.5806,     f1=0.5562,     loss=0.4192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7e412b62fa4bbeb17bce5639512c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (train) 5:   0%|| 0/1217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=38914,     correct=35659,     acc=0.9164,     recall=0.6923,     prec=0.7408,     f1=0.712,     loss=0.2238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48eb6d590bb54f6291d8f2a8655e55d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 5:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3671,     acc=0.849,     recall=0.5224,     prec=0.5574,     f1=0.5344,     loss=0.4344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c5967eca294e69b831826eed2467bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (train) 6:   0%|| 0/1217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=38914,     correct=36231,     acc=0.9311,     recall=0.7528,     prec=0.7897,     f1=0.7694,     loss=0.1871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9ec126db484042adcc412256c35ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 6:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3689,     acc=0.8531,     recall=0.5489,     prec=0.5768,     f1=0.5596,     loss=0.4868\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9ec3f2bad649ecb04a48bf65465241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (train) 7:   0%|| 0/1217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=38914,     correct=36671,     acc=0.9424,     recall=0.7925,     prec=0.8227,     f1=0.8065,     loss=0.1555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4c44e4ab57441fa6e0ff34521c6b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 7:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3703,     acc=0.8564,     recall=0.5442,     prec=0.566,     f1=0.5534,     loss=0.5017\n"
     ]
    }
   ],
   "source": [
    "trainer = BertTrainer(model, \n",
    "                      tokenizer, \n",
    "                      dataloader_train, \n",
    "                      dataloader_validation, \n",
    "                      epochs=config.epochs, \n",
    "                      lr=config.lr, \n",
    "                      output_dir=\"../model\", \n",
    "                      output_filename=\"model_state_dict.pt\", \n",
    "                      save=True)\n",
    "\n",
    "trainer.train(evaluate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b54fd664c240269dacd629c135a883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EP (eval) 0:   0%|| 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples=4324,     correct=3703,     acc=0.8564,     recall=0.5442,     prec=0.566,     f1=0.5534,     loss=0.5017\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels, label_dict):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = {key: value.to(config.device) for key, value in batch.items()}\n",
    "\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(input_ids=batch[\"input_ids\"],\n",
    "                       attention_mask=batch[\"attention_mask\"],\n",
    "                       token_type_ids=batch[\"token_type_ids\"],\n",
    "                       labels=batch[\"label\"])\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = batch['label'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "        \n",
    "    # calculate avareage val loss\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(config.device)\n",
    "data_iter = iter(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 5 5 5 5 1 5 1 5]\n",
      " [5 5 4 3 5 5 4 5 2 5 5 5 5 5 5 5 5 5 5 5 3 5 5 5 5 5 5 5 1 5 1 5]]\n",
      "Class: A2\n",
      "Accuracy: 2/2\n",
      "\n",
      "Class: B1\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: B2\n",
      "Accuracy: 0/2\n",
      "\n",
      "Class: C1\n",
      "Accuracy: 0/2\n",
      "\n",
      "Class: C2\n",
      "Accuracy: 24/25\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "batch = next(data_iter)\n",
    "batch = {key: value.to(config.device) for key, value in batch.items()}\n",
    "with torch.no_grad():        \n",
    "    outputs = model(input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                token_type_ids=batch[\"token_type_ids\"],\n",
    "                labels=batch[\"label\"])\n",
    "    logits = outputs[1].detach().cpu().numpy()\n",
    "print(np.array([logits.argmax(axis=1), batch[\"label\"].detach().cpu().numpy()]))\n",
    "print(accuracy_per_class(logits, batch[\"label\"].detach().cpu().numpy(), {\"A1\": 0, \"A2\": 1, \"B1\": 2, \"B2\": 3, \"C1\": 4, \"C2\": 5}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
